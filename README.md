# -Leveraging-Differently-Layered-Convolutional-Neural-Network-for-Speech-Emotion-Recognition
#Introduction:
The User Interaction along with the user experience has drastically changed with the integration of Voice Assistants into our Cellular Systems which is one of the closest things to Human Beings in current times[1]. The activities such as opening a web browser, turning home lights on/off, commanding to play something on an application, calling someone, etc. which was a manual task earlier has now been taken over by voice assistants like Siri, Alexa, etc.  With astonishing construe over the speech recognition system and profiling it into a voice-based assistant, apple succeeded in developing ‘Siri’, which it inculcated in iPhone 4S in the year 2011 as a feature which gave a boom to Voice Assistants exposition Initially, Virtual Assistants were developed to enable the possibility of communicating through Text with technical prospects in order to provide support services over web. Now, with transition of text into speech, Voice Assistants came to action in real-time.The well-known Voice Assistants such as Siri, Cortana, Alexa, Google Assistant, etc. operates through Oral Dialog System. This System consists 06 Modules namely, Recognition of Voice, Apprehension of Voice Language, Dialog Gaffer, Generation of Natural Language, Converted of Text to Speech, and certain Information Database. The prime visibility of Voice Assistants mirroring with leading brands motivated us to put forward and unravel varied anticipations. The paper walks you through different approaches for understanding the usefulness of Voice Assistants as well as the Internal System Progressions for decreasing Perplexity.


#Problem Statement:
-Creating voice assistant review paper and research paper for "Speech Emotion Recognition System".
-Formulating "Speech Emotion Recognition System" using differently layered CNN architectures to understand the Impact of Layers on a Dataset and integrating LSTM for better Accuracy.
-This paper aims to provide an insight upon the explorations of Voice Assistants practicality into the real-world with increased efficacy and utility. The prime visibility of Voice Assistants mirroring with leading brands motivated us to put forward and unravel varied anticipations


#vExecution:
Text, stands to be one of the prominent aspects of Communication in any Technical Phenomenon. But, with Text, understanding the Emotion of a Person, which plays a Vital role in Decision Making for actuating a Task, isn’t Possible. With the Escalated Indulgence of Speech into Diverse Technological Systems, it has been necessary to formulate a modus operandi which would precisely determine the Emotion of a Person through its Speech. Different approaches have been proposed for recognizing Emotion of a Person through Speech, but the Limitation of Modular Outlook over Speech Data seems to be Visible. In this Paper, we consummated Convolutional Neural Networks and tried to Understand the Impact of the Convolution Layers i.e., 03-Layered CNN, 04-Layered CNN, 05-Layered CNN and 06-Layered CNN, over the Speech Data and thereby formulate a Potent and an Efficient Solution for Speech Emotion Recognition. We utilized the well-known Open-Source Datasetssuch as CREMA, RAVDESS, SAVEE and TESS, consisting of Speech Audio for various Human Emotions and combined them into one whole Dataset. The outcome we got were phenomenal as the Accuracy surpassed the already existing methodologies, and also it gave us an Impactful Elucidation of its Real-time Applicability for varied Use-cases related to Speech.


# Software Requirements:
Tech Used - Python 3, Python Libraries, ML, Bluetooth, Anaconda Navigator, Tensorflow, Windows Operating System

Machine learning platforms - Speech Emotion Recognition (SER), Convolutional Neural Network (CNN), Deep Learning (DL), Natural Language Processing (NLP)

#Hardware Requirments: 
Laptop or PC, Android Phone with minimum 12 GB storage/ 4 GB ram/ Intel Graphics
